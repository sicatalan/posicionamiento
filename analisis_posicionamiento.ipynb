{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Posicionamiento de Precios\n",
    "\n",
    "Este notebook analiza el posicionamiento de precios por canal, desde una vista general (familias) hasta el detalle SKU x canal.\n",
    "\n",
    "Archivos requeridos en esta carpeta:\n",
    "- `base.xlsx`: precios por SKU y canal (columnas: sku, descripción, UMV, Marca, Canal, Fuente, Precio, Peso neto UMV, Precio unitario, Fecha).\n",
    "- `maestro_skus.xlsx`: maestro de SKUs (columnas: sku, categoria, familia).\n",
    "\n",
    "Salidas esperadas: tablas resumen, KPIs (gap absoluto y porcentual, promedios, desviaciones) y gráficos útiles para detectar desviaciones relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "# Instalación automática (si falta algo). Ejecuta esta celda si obtienes errores de importación.\n",
    "import importlib, sys, subprocess\n",
    "def ensure(pkg):\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except ImportError:\n",
    "        print(f'Instalando {pkg} ...')\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg])\n",
    "\n",
    "for p in ['pandas','numpy','openpyxl','matplotlib','seaborn','plotly']:\n",
    "    ensure(p)\n",
    "print('Dependencias listas.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "# Imports y configuración de entorno\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import unicodedata, re\n",
    "\n",
    "pd.set_option('display.max_colwidth', 120)\n",
    "pd.set_option('display.float_format', lambda x: f'{x:,.2f}')\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Funciones utilitarias\n",
    "def normalize_text(s):\n",
    "    if s is None:\n",
    "        return s\n",
    "    s = str(s)\n",
    "    s = ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c))\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r'\\s+', '_', s)\n",
    "    s = s.replace('%','pct')\n",
    "    s = re.sub(r'[^a-z0-9_]+', '', s)\n",
    "    return s\n",
    "\n",
    "def to_numeric_safe(series):\n",
    "    if series.dtype.kind in 'biufc':\n",
    "        return series\n",
    "    return pd.to_numeric(series.astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False), errors='coerce')\n",
    "\n",
    "BASE_FILE = Path('base.xlsx')\n",
    "MAESTRO_FILE = Path('maestro_skus.xlsx')\n",
    "CANAL_INTERNO = 'interno'  # nombre exacto del canal interno en la columna 'Canal'\n",
    "USAR_ULTIMA_FECHA = True   # si True, usa el último precio por SKU-Canal\n",
    "\n",
    "BASE_FILE, MAESTRO_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "# Leer base de precios\n",
    "assert BASE_FILE.exists(), f'No se encontró {BASE_FILE.resolve()}'\n",
    "try:\n",
    "    df = pd.read_excel(BASE_FILE, sheet_name=0)\n",
    "except Exception:\n",
    "    df = pd.read_excel(BASE_FILE, sheet_name='base')\n",
    "\n",
    "# Normalizar columnas\n",
    "df.columns = [normalize_text(c) for c in df.columns]\n",
    "df.rename(columns={\n",
    "    'descripcion': 'descripcion',\n",
    "    'peso_neto_umv': 'peso_neto_umv',\n",
    "    'precio_unitario': 'precio_unitario',\n",
    "    'fecha': 'fecha'\n",
    "}, inplace=True)\n",
    "\n",
    "# Tipos\n",
    "for col in ['precio', 'precio_unitario', 'peso_neto_umv']:\n",
    "    if col in df.columns:\n",
    "        df[col] = to_numeric_safe(df[col])\n",
    "\n",
    "if 'fecha' in df.columns:\n",
    "    df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')\n",
    "\n",
    "# Normalizar campo canal\n",
    "if 'canal' in df.columns:\n",
    "    df['canal'] = df['canal'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Definir precio de análisis: usa precio_unitario si existe; si no, precio/UMV si se puede, si no, precio\n",
    "if 'precio_unitario' in df.columns and df['precio_unitario'].notna().any():\n",
    "    precio_analisis = df['precio_unitario']\n",
    "else:\n",
    "    if 'precio' in df.columns and 'peso_neto_umv' in df.columns:\n",
    "        precio_analisis = df['precio'] / df['peso_neto_umv'].replace(0, np.nan)\n",
    "    else:\n",
    "        precio_analisis = df['precio'] if 'precio' in df.columns else np.nan\n",
    "df['precio_analisis'] = to_numeric_safe(precio_analisis)\n",
    "\n",
    "print('Filas en base:', len(df))\n",
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "# Leer maestro de SKUs\n",
    "assert MAESTRO_FILE.exists(), f'No se encontró {MAESTRO_FILE.resolve()}'\n",
    "maestro = pd.read_excel(MAESTRO_FILE, sheet_name=0)\n",
    "maestro.columns = [normalize_text(c) for c in maestro.columns]\n",
    "keep = [c for c in ['sku','categoria','familia'] if c in maestro.columns]\n",
    "maestro = maestro[keep].drop_duplicates()\n",
    "maestro['sku'] = maestro['sku'].astype(str).str.strip()\n",
    "print('Filas en maestro:', len(maestro))\n",
    "display(maestro.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza y selección de último precio por SKU-Canal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "# Asegurar tipos y claves de unión\n",
    "df['sku'] = df['sku'].astype(str).str.strip()\n",
    "if USAR_ULTIMA_FECHA and 'fecha' in df.columns:\n",
    "    df_sorted = df.sort_values(['sku','canal','fecha'])\n",
    "    df_latest = df_sorted.drop_duplicates(subset=['sku','canal'], keep='last')\n",
    "else:\n",
    "    df_latest = df.copy()\n",
    "\n",
    "# Merge con maestro\n",
    "data = df_latest.merge(maestro, on='sku', how='left')\n",
    "cov = data['familia'].notna().mean() if 'familia' in data.columns else np.nan\n",
    "print('Cobertura de maestro en data:', f'{cov:.1%}')\n",
    "display(data.head())\n",
    "\n",
    "# Diagnóstico general\n",
    "print('Rango de fechas:', data['fecha'].min(), '→', data['fecha'].max())\n",
    "display(data['canal'].value_counts().rename('filas_por_canal').to_frame())\n",
    "display(data.groupby('canal')['precio_analisis'].agg(['count','mean','median','std']).sort_values('mean', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación canal interno vs resto (a nivel SKU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "# Prepara precios internos y externos por SKU\n",
    "interno = (data.query('canal == @CANAL_INTERNO')[['sku','precio_analisis']]\n",
    "           .groupby('sku', as_index=False)['precio_analisis'].median()\n",
    "          ).rename(columns={'precio_analisis':'precio_interno'})\n",
    "externo = (data.query('canal != @CANAL_INTERNO')[['sku','precio_analisis','canal']]\n",
    "           .groupby('sku', as_index=False)\n",
    "           .agg(precio_externo=('precio_analisis','mean'), canales_externos=('canal','nunique'))\n",
    "          )\n",
    "\n",
    "sku_comp = maestro[['sku','categoria','familia']].merge(interno, on='sku', how='left').merge(externo, on='sku', how='left')\n",
    "sku_comp['gap_abs'] = sku_comp['precio_externo'] - sku_comp['precio_interno']\n",
    "sku_comp['gap_pct'] = np.where(sku_comp['precio_interno']>0, sku_comp['precio_externo']/sku_comp['precio_interno'] - 1, np.nan)\n",
    "\n",
    "# Estadísticas por SKU entre canales\n",
    "stats_por_sku = (data.groupby(['sku'])['precio_analisis']\n",
    "                  .agg(media_precio=('mean'), std_precio=('std'), min_precio=('min'), max_precio=('max'), conteo=('count'))\n",
    "                 )\n",
    "sku_comp = sku_comp.merge(stats_por_sku, on='sku', how='left')\n",
    "\n",
    "print('SKUs con comparables (interno y al menos un externo):',\n",
    "      ((sku_comp['precio_interno'].notna()) & (sku_comp['precio_externo'].notna())).sum())\n",
    "display(sku_comp.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top desviaciones por SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "sku_ok = sku_comp.dropna(subset=['precio_interno','precio_externo']).copy()\n",
    "top_pos = sku_ok.sort_values('gap_abs', ascending=False).head(20)\n",
    "top_neg = sku_ok.sort_values('gap_abs', ascending=True).head(20)\n",
    "display(top_pos[['sku','familia','precio_interno','precio_externo','gap_abs','gap_pct','canales_externos']])\n",
    "display(top_neg[['sku','familia','precio_interno','precio_externo','gap_abs','gap_pct','canales_externos']])\n",
    "\n",
    "fig1 = px.bar(top_pos, x='sku', y='gap_abs', color='familia', title='Top 20 SKU con mayor gap positivo (externo > interno)')\n",
    "fig1.update_layout(xaxis_title='SKU', yaxis_title='Gap absoluto')\n",
    "fig1.show()\n",
    "\n",
    "fig2 = px.bar(top_neg, x='sku', y='gap_abs', color='familia', title='Top 20 SKU con mayor gap negativo (interno > externo)')\n",
    "fig2.update_layout(xaxis_title='SKU', yaxis_title='Gap absoluto')\n",
    "fig2.show()\n",
    "\n",
    "fig3 = px.histogram(sku_ok, x='gap_pct', nbins=50, title='Distribución gap porcentual (externo vs interno)')\n",
    "fig3.update_layout(xaxis_title='Gap %', yaxis_title='Frecuencia')\n",
    "fig3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen por Familia (interno vs resto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "fam = (sku_ok.groupby('familia')\n",
    "       .agg(\n",
    "           skus=('sku','nunique'),\n",
    "           precio_interno_prom=('precio_interno','mean'),\n",
    "           precio_externo_prom=('precio_externo','mean'),\n",
    "           gap_abs_prom=('gap_abs','mean'),\n",
    "           gap_abs_med=('gap_abs','median'),\n",
    "           gap_pct_prom=('gap_pct','mean'),\n",
    "           gap_pct_med=('gap_pct','median')\n",
    "       )\n",
    "      )\n",
    "fam['gap_abs_total'] = fam['precio_externo_prom'] - fam['precio_interno_prom']\n",
    "display(fam.sort_values('gap_abs_prom', ascending=False).head(20))\n",
    "\n",
    "fig4 = px.bar(fam.reset_index().sort_values('gap_abs_prom', ascending=False).head(30),\n",
    "              x='familia', y='gap_abs_prom', title='Gap absoluto promedio por familia (Top 30)')\n",
    "fig4.update_layout(xaxis_title='Familia', yaxis_title='Gap absoluto prom.')\n",
    "fig4.show()\n",
    "\n",
    "fig5 = px.box(sku_ok, x='familia', y='gap_pct', points='outliers', title='Distribución gap % por familia')\n",
    "fig5.update_layout(xaxis={'categoryorder':'total descending'}, yaxis_title='Gap %')\n",
    "fig5.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación por Canal vs Interno (rátios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "# Pivot SKU x Canal de precios\n",
    "pivot = data.pivot_table(index='sku', columns='canal', values='precio_analisis', aggfunc='median')\n",
    "if CANAL_INTERNO not in pivot.columns:\n",
    "    print(f'Advertencia: no hay columna de canal interno = {CANAL_INTERNO!r} en los datos pivot.')\n",
    "\n",
    "ratios = {}\n",
    "for canal in pivot.columns:\n",
    "    if canal == CANAL_INTERNO:\n",
    "        continue\n",
    "    ratios[canal] = (pivot[canal] / pivot[CANAL_INTERNO])\n",
    "\n",
    "ratios_df = pd.DataFrame(ratios)\n",
    "res_canal = pd.DataFrame({\n",
    "    'ratio_promedio_vs_interno': ratios_df.mean(skipna=True),\n",
    "    'ratio_mediana_vs_interno': ratios_df.median(skipna=True),\n",
    "    'observaciones': ratios_df.count()\n",
    "}).sort_values('ratio_promedio_vs_interno', ascending=False)\n",
    "display(res_canal)\n",
    "\n",
    "fig6 = px.bar(res_canal.reset_index(), x='index', y='ratio_promedio_vs_interno', title='Promedio de (precio canal / precio interno) por canal')\n",
    "fig6.update_layout(xaxis_title='Canal', yaxis_title='Ratio promedio vs interno')\n",
    "fig6.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap: ratio por Familia y Canal (vs interno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "# Calcular ratio por SKU-Canal vs interno y luego promediar por familia\n",
    "base_ratios = data.merge(interno.rename(columns={'precio_interno':'precio_interno_ref'}), on='sku', how='left')\n",
    "base_ratios['ratio_vs_interno'] = base_ratios['precio_analisis'] / base_ratios['precio_interno_ref']\n",
    "fam_canal = (base_ratios[base_ratios['canal'] != CANAL_INTERNO]\n",
    "             .groupby(['familia','canal'])['ratio_vs_interno']\n",
    "             .mean().unstack('canal'))\n",
    "plt.figure(figsize=(12, max(4, len(fam_canal)*0.4)))\n",
    "sns.heatmap(fam_canal, annot=False, cmap='coolwarm', center=1.0)\n",
    "plt.title('Ratio promedio (precio canal / interno) por Familia y Canal')\n",
    "plt.xlabel('Canal')\n",
    "plt.ylabel('Familia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar resultados a Excel (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {"trusted": true},
   "outputs": [],
   "source": [
    "# Guardar tablas clave en 'salidas/analisis_posicionamiento.xlsx'\n",
    "out_dir = Path('salidas')\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "OUT_XLSX = out_dir / 'analisis_posicionamiento.xlsx'\n",
    "with pd.ExcelWriter(OUT_XLSX, engine='openpyxl') as wb:\n",
    "    sku_ok.to_excel(wb, sheet_name='sku_comp', index=False)\n",
    "    fam.sort_values('gap_abs_prom', ascending=False).to_excel(wb, sheet_name='familia_resumen')\n",
    "    res_canal.to_excel(wb, sheet_name='canal_vs_interno')\n",
    "print('Exportado:', OUT_XLSX.resolve())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

